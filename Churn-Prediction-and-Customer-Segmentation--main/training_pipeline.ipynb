{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3b5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, BorderlineSMOTE, KMeansSMOTE, SMOTEN, SMOTENC, SVMSMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "metrics_data_columns = ['model','sampling_method','k_neighbour', 'train_accuracy', 'test_accuracy', 'roc_auc',\n",
    "                         'precision_0', 'recall_0', 'f1_0',\n",
    "                         'precision_1', 'recall_1', 'f1_1', \n",
    "                         'ks_stat', 'p_value', \n",
    "                         'tp', 'tn', 'fp', 'fn']\n",
    "\n",
    "# actual_metrics_data_columns = ['model', 'train_accuracy', 'test_accuracy', 'roc_auc',\n",
    "#                          'precision_0', 'recall_0', 'f1_0',\n",
    "#                          'precision_1', 'recall_1', 'f1_1', \n",
    "#                          'ks_stat', 'p_value', \n",
    "#                          'tp', 'tn', 'fp', 'fn']\n",
    "\n",
    "# model_list = [ 'logistic_regression','gaussian_naive_bayes','support_vector_classifier',\n",
    "#               'ada_boost','extra_trees_classifier','gradient_boosting_classifier',\n",
    "#               'hist_gradient_boosting_classifier','random_forest_classifier',\n",
    "#               'balanced_bagging_classifier','balanced_random_forest_classifier',\n",
    "#               'easy_ensemble_classifier','lgbm_classifier','catboost_classifier']\n",
    "\n",
    "model_list = [ 'gaussian_naive_bayes', 'ada_boost','extra_trees_classifier',\n",
    "              'gradient_boosting_classifier', 'hist_gradient_boosting_classifier',\n",
    "              'random_forest_classifier','balanced_bagging_classifier',\n",
    "              'balanced_random_forest_classifier','easy_ensemble_classifier',\n",
    "              'lgbm_classifier','catboost_classifier']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb69e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_files_loc = './model_evaluations/'\n",
    "if not os.path.exists(evaluation_files_loc):\n",
    "    os.mkdir(evaluation_files_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2125e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70337e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "RowNumber                                                                  \n",
       "1                  619   42       2       0.00              1          1   \n",
       "2                  608   41       1   83807.86              1          0   \n",
       "3                  502   42       8  159660.80              3          1   \n",
       "4                  699   39       1       0.00              2          0   \n",
       "5                  850   43       2  125510.82              1          1   \n",
       "...                ...  ...     ...        ...            ...        ...   \n",
       "9996               771   39       5       0.00              2          1   \n",
       "9997               516   35      10   57369.61              1          1   \n",
       "9998               709   36       7       0.00              1          0   \n",
       "9999               772   42       3   75075.31              2          1   \n",
       "10000              792   28       4  130142.79              1          1   \n",
       "\n",
       "           IsActiveMember  EstimatedSalary  Exited  \n",
       "RowNumber                                           \n",
       "1                       1        101348.88       1  \n",
       "2                       1        112542.58       0  \n",
       "3                       0        113931.57       1  \n",
       "4                       0         93826.63       0  \n",
       "5                       1         79084.10       0  \n",
       "...                   ...              ...     ...  \n",
       "9996                    0         96270.64       0  \n",
       "9997                    1        101699.77       0  \n",
       "9998                    1         42085.58       1  \n",
       "9999                    0         92888.52       1  \n",
       "10000                   0         38190.78       0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all categorical columns\n",
    "df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f6c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation and Evaluation\n",
    "\n",
    "def features_target_split(df, target_col='Exited'):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into features and target variables.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        target_col (str): The name of the target column. Default is 'Exited'.\n",
    "        \n",
    "    Returns:\n",
    "        x (DataFrame): The features.\n",
    "        y (Series): The target variable.\n",
    "    \"\"\"\n",
    "    # Drop the target column from the DataFrame to get the features\n",
    "    x = df.drop(target_col, axis=1)\n",
    "    \n",
    "    # Assign the target column as the y variable\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Return the features and target variables\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def train_test_split(x,y,df,target_col='Exited', test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the features and target variables into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "        x (DataFrame): The features.\n",
    "        y (Series): The target variable.\n",
    "        df (DataFrame): The original DataFrame.\n",
    "        target_col (str): The name of the target column. Default is 'Exited'.\n",
    "        test_size (float or int): The proportion or absolute number of samples to include in the testing set. Default is 0.2.\n",
    "        random_state (int): The seed used by the random number generator. Default is 42.\n",
    "        \n",
    "    Returns:\n",
    "        x_train (DataFrame): The training set features.\n",
    "        x_test (DataFrame): The testing set features.\n",
    "        y_train (Series): The training set target variable.\n",
    "        y_test (Series): The testing set target variable.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Split the features and target variables into training and testing sets\n",
    "    # Stratified is being used to maintain the proportion of class [0 and 1] in splits.\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=random_state, \n",
    "                                                        stratify=df[target_col])\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def prediction(model, x_train, x_test):\n",
    "    \"\"\"\n",
    "    Generate predictions using a trained logistic regression model.\n",
    "    \n",
    "    Parameters:\n",
    "        log_reg_model (LogisticRegression): The trained logistic regression model.\n",
    "        x_train (array-like or sparse matrix): The training set features.\n",
    "        x_test (array-like or sparse matrix): The testing set features.\n",
    "        \n",
    "    Returns:\n",
    "        y_pred_train (array-like): Predicted labels for the training set.\n",
    "        y_pred_test (array-like): Predicted labels for the testing set.\n",
    "        y_pred_test_proba (array-like): Predicted probabilities for the testing set.\n",
    "    \"\"\"\n",
    "    # Generate predictions for the training set\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    \n",
    "    # Generate predictions for the testing set\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    \n",
    "    # Generate predicted probabilities for the testing set\n",
    "    y_pred_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    return y_pred_train, y_pred_test, y_pred_test_proba\n",
    "\n",
    "\n",
    "class Evaluation():\n",
    "    def __init__(self,y_train, y_test, y_pred_train, y_pred_test, y_pred_test_proba):\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.y_pred_train = y_pred_train\n",
    "        self.y_pred_test = y_pred_test\n",
    "        self.y_pred_test_proba = y_pred_test_proba\n",
    "    \n",
    "    def __ks_stats_value__(self):\n",
    "        \"\"\"\n",
    "        Calculate the Kolmogorov-Smirnov (KS) statistic and p-value.\n",
    "        \n",
    "        Returns:\n",
    "            ks_stat (float): The KS statistic.\n",
    "            p_value (float): The p-value.\n",
    "        \"\"\"\n",
    "        \n",
    "        # proba_non_churn contains the predicted probabilities for instances that did not churn\n",
    "        proba_non_churn = self.y_pred_test_proba[:,1][self.y_test==0]\n",
    "        \n",
    "        # proba_churn contains the predicted probabilities for instances that actually churned\n",
    "        proba_churn = self.y_pred_test_proba[:,1][self.y_test==1]\n",
    "        \n",
    "        # Calculating Kolmogorov-Smirnov (KS) statistic and p-value\n",
    "        ks_stat, p_value = ks_2samp(proba_non_churn, proba_churn)\n",
    "        return ks_stat, p_value\n",
    "    \n",
    "    def __accuracy_value__(self):\n",
    "        train_accuracy = accuracy_score(self.y_train, self.y_pred_train)\n",
    "        test_accuracy = accuracy_score(self.y_test, self.y_pred_test)\n",
    "        return train_accuracy, test_accuracy\n",
    "\n",
    "    def __prec_rec_f1_value__(self, pos_label):\n",
    "        \"\"\"\n",
    "        Calculate precision, recall, and F1-score for a given label.\n",
    "        \n",
    "        Parameters:\n",
    "            pos_label: The label for which metrics are calculated.\n",
    "        \n",
    "        Returns:\n",
    "            precision (float): Precision score.\n",
    "            recall (float): Recall score.\n",
    "            f1 (float): F1-score.\n",
    "        \"\"\"\n",
    "        precision = precision_score(self.y_test, self.y_pred_test,pos_label=pos_label)\n",
    "        recall = recall_score(self.y_test, self.y_pred_test,pos_label=pos_label)\n",
    "        f1 = f1_score(self.y_test, self.y_pred_test, pos_label=pos_label)\n",
    "        return precision, recall, f1\n",
    "\n",
    "    def __roc_value__(self):\n",
    "        roc_auc = roc_auc_score(self.y_test, self.y_pred_test)\n",
    "        return roc_auc\n",
    "\n",
    "    def __confusion_matrix_value__(self):\n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_test, self.y_pred_test).ravel()\n",
    "        return tn, fp, fn, tp\n",
    "    \n",
    "    def main(self):\n",
    "        train_accuracy, test_accuracy = self.__accuracy_value__()\n",
    "        \n",
    "        precision_0, recall_0, f1_0 = self.__prec_rec_f1_value__(pos_label=0)\n",
    "        precision_1, recall_1, f1_1 = self.__prec_rec_f1_value__(pos_label=1)\n",
    "        \n",
    "        ks_stat, p_value = self.__ks_stats_value__()\n",
    "        \n",
    "        roc_auc = self.__roc_value__()\n",
    "        \n",
    "        tn, fp, fn, tp = self.__confusion_matrix_value__()\n",
    "        \n",
    "        all_metrics = [train_accuracy, test_accuracy, roc_auc, \n",
    "                       precision_0, recall_0, f1_0, \n",
    "                       precision_1, recall_1, f1_1, \n",
    "                       ks_stat, p_value, \n",
    "                       tp, tn, fp, fn]\n",
    "        \n",
    "        all_metrics = [round(value, ndigits=6) for value in all_metrics]\n",
    "        all_metrics_dict = {'train_acc':all_metrics[0], 'test_acc':all_metrics[1], 'roc_auc':all_metrics[2],  \n",
    "                            'class_0':{'precision':all_metrics[3], 'recall':all_metrics[4], 'f1':all_metrics[5]}, \n",
    "                            'class_1':{'precision':all_metrics[6], 'recall':all_metrics[7], 'f1':all_metrics[8]},\n",
    "                            'ks_stats':all_metrics[9], 'p_value':all_metrics[10],\n",
    "                            'tp':all_metrics[11],'tn':all_metrics[12],'fp':all_metrics[13],'fn':all_metrics[14]}\n",
    "        \n",
    "        return all_metrics, all_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d715555",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11bd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_model_train(x_train, y_train, random_state=42, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model using the provided training data.\n",
    "    \n",
    "    Parameters:\n",
    "        x_train (DataFrame): The training set features.\n",
    "        y_train (Series): The training set target variable.\n",
    "        random_state (int): The seed used by the random number generator. Default is 42.\n",
    "        max_iter (int): The maximum number of iterations for the solver to converge. Default is 1000.\n",
    "        \n",
    "    Returns:\n",
    "        log_reg_model (LogisticRegression): The trained logistic regression model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an instance of LogisticRegression model with specified random_state and max_iter\n",
    "    log_reg_model = LogisticRegression(random_state=random_state, max_iter=max_iter)\n",
    "    \n",
    "    # Fit the logistic regression model to the training data\n",
    "    log_reg_model.fit(x_train, y_train)\n",
    "    \n",
    "    return log_reg_model\n",
    "\n",
    "\n",
    "def gnb_model_train(x_train, y_train):\n",
    "    \n",
    "    # instantiate the model\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    return gnb\n",
    "\n",
    "def svc_model_train(x_train, y_train, random_state=42):\n",
    "\n",
    "    svc = SVC(probability=True,random_state=random_state)\n",
    "    svc.fit(x_train, y_train)\n",
    "    return svc\n",
    "\n",
    "def adaboost_model_train(x_train, y_train, random_state=42):\n",
    "\n",
    "    adb_model = AdaBoostClassifier(random_state=random_state)\n",
    "    adb_model.fit(x_train, y_train)\n",
    "    return adb_model\n",
    "\n",
    "def etc_model_train(x_train, y_train, random_state=42):\n",
    "    etc_model = ExtraTreesClassifier(random_state=random_state)\n",
    "    etc_model.fit(x_train, y_train)\n",
    "    return etc_model\n",
    "\n",
    "def gbc_model_train(x_train, y_train, random_state=42):\n",
    "    gbc_model = GradientBoostingClassifier(random_state=random_state)\n",
    "    gbc_model.fit(x_train, y_train)\n",
    "    return gbc_model\n",
    "\n",
    "def hgbc_model_train(x_train, y_train, random_state=42):\n",
    "    hgbc_model = HistGradientBoostingClassifier(random_state=random_state)\n",
    "    hgbc_model.fit(x_train, y_train)\n",
    "    return hgbc_model\n",
    "\n",
    "def rfc_model_train(x_train, y_train, random_state=42):\n",
    "    rfc_model = RandomForestClassifier(random_state=random_state)\n",
    "    rfc_model.fit(x_train, y_train)\n",
    "    return rfc_model\n",
    "\n",
    "def bbc_model_train(x_train, y_train, random_state=42):\n",
    "    bbc_model = BalancedBaggingClassifier(random_state=random_state)\n",
    "    bbc_model.fit(x_train, y_train)\n",
    "    return bbc_model\n",
    "\n",
    "def brfc_model_train(x_train, y_train, random_state=42):\n",
    "    brfc_model = BalancedRandomForestClassifier(random_state=random_state)\n",
    "    brfc_model.fit(x_train, y_train)\n",
    "    return brfc_model\n",
    "\n",
    "def eec_model_train(x_train, y_train, random_state=42):\n",
    "    eec_model = EasyEnsembleClassifier(random_state=random_state)\n",
    "    eec_model.fit(x_train, y_train)\n",
    "    return eec_model\n",
    "\n",
    "def lgbm_model_train(x_train, y_train, random_state=42):\n",
    "    lgbm_model = LGBMClassifier(random_state=random_state)\n",
    "    lgbm_model.fit(x_train, y_train)\n",
    "    return lgbm_model\n",
    "\n",
    "def catboost_model_train(x_train, y_train, random_state=42):\n",
    "    catboost_model = CatBoostClassifier(random_state=random_state)\n",
    "    catboost_model.fit(x_train, y_train, verbose=False)\n",
    "    return catboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2967a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_models(x_train, y_train, model_name):\n",
    "    \n",
    "    if model_name == 'logistic_regression':\n",
    "        model = logistic_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'gaussian_naive_bayes':\n",
    "        model = gnb_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'support_vector_classifier':\n",
    "        model = svc_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'ada_boost':\n",
    "        model = adaboost_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'extra_trees_classifier':\n",
    "        model = etc_model_train(x_train, y_train)\n",
    "\n",
    "    elif model_name == 'gradient_boosting_classifier':\n",
    "        model = gbc_model_train(x_train, y_train)\n",
    "    \n",
    "    elif model_name == 'hist_gradient_boosting_classifier':\n",
    "        model = hgbc_model_train(x_train, y_train)\n",
    "    \n",
    "    elif model_name == 'random_forest_classifier':\n",
    "        model = rfc_model_train(x_train, y_train)\n",
    "\n",
    "    elif model_name == 'balanced_bagging_classifier':\n",
    "        model = bbc_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'balanced_random_forest_classifier':\n",
    "        model = brfc_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'easy_ensemble_classifier':\n",
    "        model = eec_model_train(x_train, y_train)\n",
    "\n",
    "    elif model_name == 'lgbm_classifier':\n",
    "        model = lgbm_model_train(x_train, y_train)\n",
    "\n",
    "    elif model_name == 'catboost_classifier':\n",
    "        model = catboost_model_train(x_train, y_train)\n",
    "\n",
    "    else:\n",
    "        print(\"Check model name\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfede73",
   "metadata": {},
   "source": [
    "## Class Balancing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cdb8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_method(x,y,neighbour):\n",
    "    # Apply SMOTE\n",
    "    sm = SMOTE(random_state=42, k_neighbors=neighbour)\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def adasyn_method(x,y,neighbour):\n",
    "    adap_synt = ADASYN(random_state=42, n_neighbors=neighbour)\n",
    "    x_new, y_new = adap_synt.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def borderline_smote_method(x,y,neighbour):\n",
    "    border_smote = BorderlineSMOTE(random_state=42, k_neighbors=neighbour)\n",
    "    x_new, y_new = border_smote.fit_resample(x,y)\n",
    "\n",
    "    return x_new, y_new\n",
    "\n",
    "def kmeans_smote_method(x,y,neighbour):\n",
    "    kmeans_smote = KMeansSMOTE(random_state=42, k_neighbors=neighbour,cluster_balance_threshold=0.2)\n",
    "    x_new, y_new = kmeans_smote.fit_resample(x,y)\n",
    "\n",
    "    return x_new, y_new\n",
    "\n",
    "def smoten_method(x,y,neighbour):\n",
    "    # Apply SMOTEN\n",
    "    sm = SMOTEN(random_state=42, k_neighbors=neighbour)\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def smotenc_method(x,y,neighbour, approach_type):\n",
    "    \n",
    "    # File location of the dataset\n",
    "    data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "    # Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "    df = pd.read_csv(data_loc, index_col=0)\n",
    "    \n",
    "    df.drop(['CustomerId'], axis = 1,inplace=True)\n",
    "    \n",
    "    if approach_type == 1:\n",
    "    \n",
    "        x,y = features_target_split(df)\n",
    "\n",
    "        # Apply SMOTENC\n",
    "        sm = SMOTENC(categorical_features=[0,2,3],random_state=42, k_neighbors=neighbour)\n",
    "        x_new, y_new = sm.fit_resample(x,y)\n",
    "\n",
    "        x_new.drop(['Surname', 'Geography', 'Gender'], axis = 1,inplace=True)\n",
    "        \n",
    "        return x_new, y_new\n",
    "    \n",
    "    if approach_type == 2:\n",
    "        x,y = features_target_split(df)\n",
    "        \n",
    "        # Split the features and target variables into training and testing sets.\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "        # Apply SMOTENC\n",
    "        sm = SMOTENC(categorical_features=[0,2,3],random_state=42, k_neighbors=neighbour)\n",
    "        x_train_new, y_train_new = sm.fit_resample(x_train,y_train)\n",
    "\n",
    "        x_train_new.drop(['Surname', 'Geography', 'Gender'], axis = 1,inplace=True)\n",
    "        \n",
    "        x_test.drop(['Surname', 'Geography', 'Gender'], axis = 1,inplace=True)\n",
    "        \n",
    "        return x_train_new, x_test, y_train_new, y_test \n",
    "\n",
    "def svm_smote_method(x,y,neighbour):\n",
    "    # Apply SVMSMOTE\n",
    "    sm = SVMSMOTE(random_state=42, k_neighbors=neighbour)\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def smote_enn_method(x,y,neighbour):\n",
    "    # Apply SMOTEENN\n",
    "    sm = SMOTEENN(random_state=42, smote=SMOTE(random_state=42, k_neighbors=neighbour))\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def smote_tomek_method(x,y,neighbour):\n",
    "    # Apply SMOTETOMEK\n",
    "    sm = SMOTETomek(random_state=42, smote=SMOTE(random_state=42, k_neighbors=neighbour))\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be656b1",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3806d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4304fbf",
   "metadata": {},
   "source": [
    "# Using actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c2e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC_REGRESSION                      :: Train Acc: 0.79625        :: Test Acc: 0.7965\n",
      "GAUSSIAN_NAIVE_BAYES                     :: Train Acc: 0.784375       :: Test Acc: 0.784\n",
      "SUPPORT_VECTOR_CLASSIFIER                :: Train Acc: 0.79625        :: Test Acc: 0.7965\n",
      "ADA_BOOST                                :: Train Acc: 0.848375       :: Test Acc: 0.844\n",
      "EXTRA_TREES_CLASSIFIER                   :: Train Acc: 1.0            :: Test Acc: 0.847\n",
      "GRADIENT_BOOSTING_CLASSIFIER             :: Train Acc: 0.86375        :: Test Acc: 0.8605\n",
      "HIST_GRADIENT_BOOSTING_CLASSIFIER        :: Train Acc: 0.900875       :: Test Acc: 0.8505\n",
      "RANDOM_FOREST_CLASSIFIER                 :: Train Acc: 1.0            :: Test Acc: 0.8545\n",
      "BALANCED_BAGGING_CLASSIFIER              :: Train Acc: 0.93125        :: Test Acc: 0.795\n",
      "BALANCED_RANDOM_FOREST_CLASSIFIER        :: Train Acc: 0.89725        :: Test Acc: 0.7675\n",
      "EASY_ENSEMBLE_CLASSIFIER                 :: Train Acc: 0.772          :: Test Acc: 0.77\n",
      "LGBM_CLASSIFIER                          :: Train Acc: 0.90525        :: Test Acc: 0.855\n",
      "CATBOOST_CLASSIFIER                      :: Train Acc: 0.896875       :: Test Acc: 0.859\n"
     ]
    }
   ],
   "source": [
    "actual_metrics_data = []\n",
    "for model_name in model_list:\n",
    "    model = train_all_models(x_train, y_train, model_name)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred_train, y_pred_test, y_pred_test_proba = prediction(model, x_train, x_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    model_evaluation = Evaluation(y_train, y_test, y_pred_train, y_pred_test, y_pred_test_proba)\n",
    "    \n",
    "    all_metrics,_ = model_evaluation.main()\n",
    "    all_metrics.insert(0, model_name)\n",
    "    \n",
    "    print(\"{:<40} :: Train Acc: {:<14} :: Test Acc: {}\".format(model_name.upper(), all_metrics[1], all_metrics[2]) )\n",
    "\n",
    "    actual_metrics_data.append(all_metrics)\n",
    "#     break\n",
    "    \n",
    "metrics_df = pd.DataFrame(actual_metrics_data, columns=actual_metrics_data_columns)\n",
    "metrics_df.to_csv('./models_evaluation_actual_data.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba364b1c",
   "metadata": {},
   "source": [
    "# Using Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc0544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc023f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_method(method_name, neighbour, x_train, y_train):\n",
    "    \n",
    "#     print(f\"\\nUsing {method_name.upper()} :: APPROACH 2 :: \")\n",
    "\n",
    "    if method_name == 'smote':\n",
    "        # Apply SMOTE\n",
    "        x_train_new, y_train_new = smote_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'adasyn':\n",
    "        # Apply ADASYN\n",
    "        x_train_new, y_train_new = adasyn_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'borderline_smote':\n",
    "        # Apply Borderline SMOTE\n",
    "        x_train_new, y_train_new = borderline_smote_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'kmeans_smote':\n",
    "        # Apply KMeans SMOTE\n",
    "        x_train_new, y_train_new = kmeans_smote_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'smoten':\n",
    "        # Apply SMOTEN\n",
    "        x_train_new, y_train_new = smoten_method(x_train,y_train,neighbour)\n",
    "\n",
    "#     if method_name == 'smotenc':\n",
    "#         # Apply SMOTENC\n",
    "#         x_train_new, x_test, y_train_new, y_test = smotenc_method(x_train,y_train,neighbour, approach_type=2)\n",
    "\n",
    "    if method_name == 'svmsmote':\n",
    "        # Apply SVMSMOTE\n",
    "        x_train_new, y_train_new = svm_smote_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'smoteenn':\n",
    "        # Apply SMOTEENN\n",
    "        x_train_new, y_train_new = smote_enn_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'smotetomek':\n",
    "        # Apply SMOTETOMEK\n",
    "        x_train_new, y_train_new = smote_tomek_method(x_train,y_train,neighbour)\n",
    "    \n",
    "    \n",
    "    return x_train_new, y_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe733f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_ = ['smote', 'adasyn', 'borderline_smote', 'kmeans_smote', 'smoten' , 'svmsmote', 'smoteenn', 'smotetomek']\n",
    "# k_values = [273, 1020, 1409, 110, 282, 148, 1, 116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023e0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac0088d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_data = []\n",
    "for model_name in model_list:\n",
    "    print(model_name.upper())\n",
    "    \n",
    "    for mth in methods_:\n",
    "        if mth == 'kmeans_smote':\n",
    "            # No cluster are formed beyond this value of k\n",
    "            stop_range = 339\n",
    "        \n",
    "        elif mth == 'smotenc':\n",
    "            # RAM issue\n",
    "            stop_range = 150\n",
    "        \n",
    "        else:\n",
    "            stop_range = y_train.value_counts()[1]\n",
    "\n",
    "\n",
    "        for neighbour in range(1,stop_range):\n",
    "            x_train_new, y_train_new = sampling_method(mth, neighbour)\n",
    "\n",
    "            model = train_all_models(x_train_new, y_train_new, model_name)\n",
    "\n",
    "            # Generate predictions\n",
    "            y_pred_train, y_pred_test, y_pred_test_proba = prediction(model, x_train_new, x_test)\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            model_evaluation = Evaluation(y_train_new, y_test, y_pred_train, y_pred_test, y_pred_test_proba)\n",
    "\n",
    "            all_metrics,_ = model_evaluation.main()\n",
    "            all_metrics.insert(0, model_name)\n",
    "            all_metrics.insert(1, mth)\n",
    "            all_metrics.insert(2, neighbour)\n",
    "    \n",
    "            if neighbour%500 == 0 or neighbour == 1:\n",
    "                print(\"{:<40} :: Train Acc: {:<14} :: Test Acc: {}\".format(mth.upper(), all_metrics[3], all_metrics[4]))\n",
    "\n",
    "            metrics_data.append(all_metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=metrics_data_columns)\n",
    "metrics_df.to_csv('./models_evaluation_sampled_data_all.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d052887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SMOTE\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "   \n",
    "# for mth in methods_:\n",
    "#     print('\\n',mth.upper())\n",
    "#     metrics_data = [] \n",
    "#     if mth == 'kmeans_smote':\n",
    "#         # No cluster are formed beyond this value of k\n",
    "#         stop_range = 339\n",
    "\n",
    "#     elif mth == 'smotenc':\n",
    "#         # RAM issue\n",
    "#         stop_range = 150\n",
    "\n",
    "#     else:\n",
    "#         stop_range = y_train.value_counts()[1]\n",
    "\n",
    "\n",
    "#     for neighbour in range(1,stop_range):\n",
    "#         x_train_new, y_train_new = sampling_method(mth, neighbour)\n",
    "        \n",
    "#         for model_name in model_list:\n",
    "# #             print(model_name.upper())\n",
    "\n",
    "#             model = train_all_models(x_train_new, y_train_new, model_name)\n",
    "\n",
    "#             # Generate predictions\n",
    "#             y_pred_train, y_pred_test, y_pred_test_proba = prediction(model, x_train_new, x_test)\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             model_evaluation = Evaluation(y_train_new, y_test, y_pred_train, y_pred_test, y_pred_test_proba)\n",
    "\n",
    "#             all_metrics,_ = model_evaluation.main()\n",
    "#             all_metrics.insert(0, model_name)\n",
    "#             all_metrics.insert(1, mth)\n",
    "#             all_metrics.insert(2, neighbour)\n",
    "\n",
    "# #             if neighbour%500 == 0 or neighbour == 1:\n",
    "# #                 print(\"{:<40} :: Train Acc: {:<14} :: Test Acc: {}\".format(mth.upper(), all_metrics[3], all_metrics[4]))\n",
    "\n",
    "#             metrics_data.append(all_metrics)\n",
    "#         print('.',end='')\n",
    "\n",
    "#     metrics_df = pd.DataFrame(metrics_data, columns=metrics_data_columns)\n",
    "#     metrics_df.to_csv(f'./all_methods_models/{mth}_models_evaluation_all.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbc900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc052d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
