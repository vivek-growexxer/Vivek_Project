{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3b5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from time import time\n",
    "import multiprocessing\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, BorderlineSMOTE, KMeansSMOTE, SMOTEN, SMOTENC, SVMSMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "metrics_data_columns = ['model','sampling_method','k_neighbour', 'train_accuracy', 'test_accuracy', 'roc_auc',\n",
    "                         'precision_0', 'recall_0', 'f1_0',\n",
    "                         'precision_1', 'recall_1', 'f1_1', \n",
    "                         'ks_stat', 'p_value', \n",
    "                         'tp', 'tn', 'fp', 'fn']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b6e42",
   "metadata": {},
   "source": [
    "## Data preperation and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f6c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation and Evaluation\n",
    "\n",
    "def features_target_split(df, target_col='Exited'):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into features and target variables.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        target_col (str): The name of the target column. Default is 'Exited'.\n",
    "        \n",
    "    Returns:\n",
    "        x (DataFrame): The features.\n",
    "        y (Series): The target variable.\n",
    "    \"\"\"\n",
    "    # Drop the target column from the DataFrame to get the features\n",
    "    x = df.drop(target_col, axis=1)\n",
    "    \n",
    "    # Assign the target column as the y variable\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Return the features and target variables\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def train_test_split(x,y,df,target_col='Exited', test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the features and target variables into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "        x (DataFrame): The features.\n",
    "        y (Series): The target variable.\n",
    "        df (DataFrame): The original DataFrame.\n",
    "        target_col (str): The name of the target column. Default is 'Exited'.\n",
    "        test_size (float or int): The proportion or absolute number of samples to include in the testing set. Default is 0.2.\n",
    "        random_state (int): The seed used by the random number generator. Default is 42.\n",
    "        \n",
    "    Returns:\n",
    "        x_train (DataFrame): The training set features.\n",
    "        x_test (DataFrame): The testing set features.\n",
    "        y_train (Series): The training set target variable.\n",
    "        y_test (Series): The testing set target variable.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Split the features and target variables into training and testing sets\n",
    "    # Stratified is being used to maintain the proportion of class [0 and 1] in splits.\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=random_state, \n",
    "                                                        stratify=df[target_col])\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def prediction(model, x_train, x_test):\n",
    "    \"\"\"\n",
    "    Generate predictions using a trained logistic regression model.\n",
    "    \n",
    "    Parameters:\n",
    "        log_reg_model (LogisticRegression): The trained logistic regression model.\n",
    "        x_train (array-like or sparse matrix): The training set features.\n",
    "        x_test (array-like or sparse matrix): The testing set features.\n",
    "        \n",
    "    Returns:\n",
    "        y_pred_train (array-like): Predicted labels for the training set.\n",
    "        y_pred_test (array-like): Predicted labels for the testing set.\n",
    "        y_pred_test_proba (array-like): Predicted probabilities for the testing set.\n",
    "    \"\"\"\n",
    "    # Generate predictions for the training set\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    \n",
    "    # Generate predictions for the testing set\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    \n",
    "    # Generate predicted probabilities for the testing set\n",
    "    y_pred_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    return y_pred_train, y_pred_test, y_pred_test_proba\n",
    "\n",
    "\n",
    "class Evaluation():\n",
    "    def __init__(self,y_train, y_test, y_pred_train, y_pred_test, y_pred_test_proba):\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.y_pred_train = y_pred_train\n",
    "        self.y_pred_test = y_pred_test\n",
    "        self.y_pred_test_proba = y_pred_test_proba\n",
    "    \n",
    "    def __ks_stats_value__(self):\n",
    "        \"\"\"\n",
    "        Calculate the Kolmogorov-Smirnov (KS) statistic and p-value.\n",
    "        \n",
    "        Returns:\n",
    "            ks_stat (float): The KS statistic.\n",
    "            p_value (float): The p-value.\n",
    "        \"\"\"\n",
    "        \n",
    "        # proba_non_churn contains the predicted probabilities for instances that did not churn\n",
    "        proba_non_churn = self.y_pred_test_proba[:,1][self.y_test==0]\n",
    "        \n",
    "        # proba_churn contains the predicted probabilities for instances that actually churned\n",
    "        proba_churn = self.y_pred_test_proba[:,1][self.y_test==1]\n",
    "        \n",
    "        # Calculating Kolmogorov-Smirnov (KS) statistic and p-value\n",
    "        ks_stat, p_value = ks_2samp(proba_non_churn, proba_churn)\n",
    "        return ks_stat, p_value\n",
    "    \n",
    "    def __accuracy_value__(self):\n",
    "        train_accuracy = accuracy_score(self.y_train, self.y_pred_train)\n",
    "        test_accuracy = accuracy_score(self.y_test, self.y_pred_test)\n",
    "        return train_accuracy, test_accuracy\n",
    "\n",
    "    def __prec_rec_f1_value__(self, pos_label):\n",
    "        \"\"\"\n",
    "        Calculate precision, recall, and F1-score for a given label.\n",
    "        \n",
    "        Parameters:\n",
    "            pos_label: The label for which metrics are calculated.\n",
    "        \n",
    "        Returns:\n",
    "            precision (float): Precision score.\n",
    "            recall (float): Recall score.\n",
    "            f1 (float): F1-score.\n",
    "        \"\"\"\n",
    "        precision = precision_score(self.y_test, self.y_pred_test,pos_label=pos_label)\n",
    "        recall = recall_score(self.y_test, self.y_pred_test,pos_label=pos_label)\n",
    "        f1 = f1_score(self.y_test, self.y_pred_test, pos_label=pos_label)\n",
    "        return precision, recall, f1\n",
    "\n",
    "    def __roc_value__(self):\n",
    "        roc_auc = roc_auc_score(self.y_test, self.y_pred_test)\n",
    "        return roc_auc\n",
    "\n",
    "    def __confusion_matrix_value__(self):\n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_test, self.y_pred_test).ravel()\n",
    "        return tn, fp, fn, tp\n",
    "    \n",
    "    def main(self):\n",
    "        train_accuracy, test_accuracy = self.__accuracy_value__()\n",
    "        \n",
    "        precision_0, recall_0, f1_0 = self.__prec_rec_f1_value__(pos_label=0)\n",
    "        precision_1, recall_1, f1_1 = self.__prec_rec_f1_value__(pos_label=1)\n",
    "        \n",
    "        ks_stat, p_value = self.__ks_stats_value__()\n",
    "        \n",
    "        roc_auc = self.__roc_value__()\n",
    "        \n",
    "        tn, fp, fn, tp = self.__confusion_matrix_value__()\n",
    "        \n",
    "        all_metrics = [train_accuracy, test_accuracy, roc_auc, \n",
    "                       precision_0, recall_0, f1_0, \n",
    "                       precision_1, recall_1, f1_1, \n",
    "                       ks_stat, p_value, \n",
    "                       tp, tn, fp, fn]\n",
    "        \n",
    "        all_metrics = [round(value, ndigits=6) for value in all_metrics]\n",
    "        all_metrics_dict = {'train_acc':all_metrics[0], 'test_acc':all_metrics[1], 'roc_auc':all_metrics[2],  \n",
    "                            'class_0':{'precision':all_metrics[3], 'recall':all_metrics[4], 'f1':all_metrics[5]}, \n",
    "                            'class_1':{'precision':all_metrics[6], 'recall':all_metrics[7], 'f1':all_metrics[8]},\n",
    "                            'ks_stats':all_metrics[9], 'p_value':all_metrics[10],\n",
    "                            'tp':all_metrics[11],'tn':all_metrics[12],'fp':all_metrics[13],'fn':all_metrics[14]}\n",
    "        \n",
    "        return all_metrics, all_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d715555",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b11bd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_model_train(x_train, y_train, random_state=42, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model using the provided training data.\n",
    "    \n",
    "    Parameters:\n",
    "        x_train (DataFrame): The training set features.\n",
    "        y_train (Series): The training set target variable.\n",
    "        random_state (int): The seed used by the random number generator. Default is 42.\n",
    "        max_iter (int): The maximum number of iterations for the solver to converge. Default is 1000.\n",
    "        \n",
    "    Returns:\n",
    "        log_reg_model (LogisticRegression): The trained logistic regression model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an instance of LogisticRegression model with specified random_state and max_iter\n",
    "    log_reg_model = LogisticRegression(random_state=random_state, max_iter=max_iter)\n",
    "    \n",
    "    # Fit the logistic regression model to the training data\n",
    "    log_reg_model.fit(x_train, y_train)\n",
    "    \n",
    "    return log_reg_model\n",
    "\n",
    "\n",
    "def gnb_model_train(x_train, y_train):\n",
    "    \n",
    "    # instantiate the model\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    return gnb\n",
    "\n",
    "def svc_model_train(x_train, y_train, random_state=42):\n",
    "\n",
    "    svc = SVC(probability=True,random_state=random_state)\n",
    "    svc.fit(x_train, y_train)\n",
    "    return svc\n",
    "\n",
    "def adaboost_model_train(x_train, y_train, random_state=42):\n",
    "\n",
    "    adb_model = AdaBoostClassifier(random_state=random_state)\n",
    "    adb_model.fit(x_train, y_train)\n",
    "    return adb_model\n",
    "\n",
    "def etc_model_train(x_train, y_train, random_state=42):\n",
    "    etc_model = ExtraTreesClassifier(random_state=random_state)\n",
    "    etc_model.fit(x_train, y_train)\n",
    "    return etc_model\n",
    "\n",
    "def gbc_model_train(x_train, y_train, random_state=42):\n",
    "    gbc_model = GradientBoostingClassifier(random_state=random_state)\n",
    "    gbc_model.fit(x_train, y_train)\n",
    "    return gbc_model\n",
    "\n",
    "def hgbc_model_train(x_train, y_train, random_state=42):\n",
    "    hgbc_model = HistGradientBoostingClassifier(random_state=random_state)\n",
    "    hgbc_model.fit(x_train, y_train)\n",
    "    return hgbc_model\n",
    "\n",
    "def rfc_model_train(x_train, y_train, random_state=42):\n",
    "    rfc_model = RandomForestClassifier(random_state=random_state)\n",
    "    rfc_model.fit(x_train, y_train)\n",
    "    return rfc_model\n",
    "\n",
    "def bbc_model_train(x_train, y_train, random_state=42):\n",
    "    bbc_model = BalancedBaggingClassifier(random_state=random_state)\n",
    "    bbc_model.fit(x_train, y_train)\n",
    "    return bbc_model\n",
    "\n",
    "def brfc_model_train(x_train, y_train, random_state=42):\n",
    "    brfc_model = BalancedRandomForestClassifier(random_state=random_state)\n",
    "    brfc_model.fit(x_train, y_train)\n",
    "    return brfc_model\n",
    "\n",
    "def eec_model_train(x_train, y_train, random_state=42):\n",
    "    eec_model = EasyEnsembleClassifier(random_state=random_state)\n",
    "    eec_model.fit(x_train, y_train)\n",
    "    return eec_model\n",
    "\n",
    "def lgbm_model_train(x_train, y_train, random_state=42):\n",
    "    lgbm_model = LGBMClassifier(random_state=random_state)\n",
    "    lgbm_model.fit(x_train, y_train)\n",
    "    return lgbm_model\n",
    "\n",
    "def catboost_model_train(x_train, y_train, random_state=42):\n",
    "    catboost_model = CatBoostClassifier(random_state=random_state)\n",
    "    catboost_model.fit(x_train, y_train, verbose=False)\n",
    "    return catboost_model\n",
    "\n",
    "def train_all_models(x_train, y_train, model_name):\n",
    "    \n",
    "    if model_name == 'logistic_regression':\n",
    "        model = logistic_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'gaussian_naive_bayes':\n",
    "        model = gnb_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'support_vector_classifier':\n",
    "        model = svc_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'ada_boost':\n",
    "        model = adaboost_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'extra_trees_classifier':\n",
    "        model = etc_model_train(x_train, y_train)\n",
    "\n",
    "    elif model_name == 'gradient_boosting_classifier':\n",
    "        model = gbc_model_train(x_train, y_train)\n",
    "    \n",
    "    elif model_name == 'hist_gradient_boosting_classifier':\n",
    "        model = hgbc_model_train(x_train, y_train)\n",
    "    \n",
    "    elif model_name == 'random_forest_classifier':\n",
    "        model = rfc_model_train(x_train, y_train)\n",
    "\n",
    "    elif model_name == 'balanced_bagging_classifier':\n",
    "        model = bbc_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'balanced_random_forest_classifier':\n",
    "        model = brfc_model_train(x_train, y_train)\n",
    "        \n",
    "    elif model_name == 'easy_ensemble_classifier':\n",
    "        model = eec_model_train(x_train, y_train)\n",
    "\n",
    "    elif model_name == 'lgbm_classifier':\n",
    "        model = lgbm_model_train(x_train, y_train)\n",
    "\n",
    "    elif model_name == 'catboost_classifier':\n",
    "        model = catboost_model_train(x_train, y_train)\n",
    "\n",
    "    else:\n",
    "        print(\"Check model name\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfede73",
   "metadata": {},
   "source": [
    "## Class Balancing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cdb8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_method(x,y,neighbour):\n",
    "    # Apply SMOTE\n",
    "    sm = SMOTE(random_state=42, k_neighbors=neighbour)\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def adasyn_method(x,y,neighbour):\n",
    "    adap_synt = ADASYN(random_state=42, n_neighbors=neighbour)\n",
    "    x_new, y_new = adap_synt.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def borderline_smote_method(x,y,neighbour):\n",
    "    border_smote = BorderlineSMOTE(random_state=42, k_neighbors=neighbour)\n",
    "    x_new, y_new = border_smote.fit_resample(x,y)\n",
    "\n",
    "    return x_new, y_new\n",
    "\n",
    "def kmeans_smote_method(x,y,neighbour):\n",
    "    kmeans_smote = KMeansSMOTE(random_state=42, k_neighbors=neighbour,cluster_balance_threshold=0.2)\n",
    "    x_new, y_new = kmeans_smote.fit_resample(x,y)\n",
    "\n",
    "    return x_new, y_new\n",
    "\n",
    "def smoten_method(x,y,neighbour):\n",
    "    # Apply SMOTEN\n",
    "    sm = SMOTEN(random_state=42, k_neighbors=neighbour)\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def smotenc_method(x,y,neighbour, approach_type):\n",
    "    \n",
    "    # File location of the dataset\n",
    "    data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "    # Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "    df = pd.read_csv(data_loc, index_col=0)\n",
    "    \n",
    "    df.drop(['CustomerId'], axis = 1,inplace=True)\n",
    "    \n",
    "    if approach_type == 1:\n",
    "    \n",
    "        x,y = features_target_split(df)\n",
    "\n",
    "        # Apply SMOTENC\n",
    "        sm = SMOTENC(categorical_features=[0,2,3],random_state=42, k_neighbors=neighbour)\n",
    "        x_new, y_new = sm.fit_resample(x,y)\n",
    "\n",
    "        x_new.drop(['Surname', 'Geography', 'Gender'], axis = 1,inplace=True)\n",
    "        \n",
    "        return x_new, y_new\n",
    "    \n",
    "    if approach_type == 2:\n",
    "        x,y = features_target_split(df)\n",
    "        \n",
    "        # Split the features and target variables into training and testing sets.\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "        # Apply SMOTENC\n",
    "        sm = SMOTENC(categorical_features=[0,2,3],random_state=42, k_neighbors=neighbour)\n",
    "        x_train_new, y_train_new = sm.fit_resample(x_train,y_train)\n",
    "\n",
    "        x_train_new.drop(['Surname', 'Geography', 'Gender'], axis = 1,inplace=True)\n",
    "        \n",
    "        x_test.drop(['Surname', 'Geography', 'Gender'], axis = 1,inplace=True)\n",
    "        \n",
    "        return x_train_new, x_test, y_train_new, y_test \n",
    "\n",
    "def svm_smote_method(x,y,neighbour):\n",
    "    # Apply SVMSMOTE\n",
    "    sm = SVMSMOTE(random_state=42, k_neighbors=neighbour)\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def smote_enn_method(x,y,neighbour):\n",
    "    # Apply SMOTEENN\n",
    "    sm = SMOTEENN(random_state=42, smote=SMOTE(random_state=42, k_neighbors=neighbour))\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def smote_tomek_method(x,y,neighbour):\n",
    "    # Apply SMOTETOMEK\n",
    "    sm = SMOTETomek(random_state=42, smote=SMOTE(random_state=42, k_neighbors=neighbour))\n",
    "    x_new, y_new = sm.fit_resample(x,y)\n",
    "    \n",
    "    return x_new, y_new\n",
    "\n",
    "def sampling_method(method_name, neighbour, x_train, y_train):\n",
    "    \n",
    "#     print(f\"\\nUsing {method_name.upper()} :: APPROACH 2 :: \")\n",
    "\n",
    "    if method_name == 'smote':\n",
    "        # Apply SMOTE\n",
    "        x_train_new, y_train_new = smote_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'adasyn':\n",
    "        # Apply ADASYN\n",
    "        x_train_new, y_train_new = adasyn_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'borderline_smote':\n",
    "        # Apply Borderline SMOTE\n",
    "        x_train_new, y_train_new = borderline_smote_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'kmeans_smote':\n",
    "        # Apply KMeans SMOTE\n",
    "        x_train_new, y_train_new = kmeans_smote_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'smoten':\n",
    "        # Apply SMOTEN\n",
    "        x_train_new, y_train_new = smoten_method(x_train,y_train,neighbour)\n",
    "\n",
    "#     if method_name == 'smotenc':\n",
    "#         # Apply SMOTENC\n",
    "#         x_train_new, x_test, y_train_new, y_test = smotenc_method(x_train,y_train,neighbour, approach_type=2)\n",
    "\n",
    "    if method_name == 'svmsmote':\n",
    "        # Apply SVMSMOTE\n",
    "        x_train_new, y_train_new = svm_smote_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'smoteenn':\n",
    "        # Apply SMOTEENN\n",
    "        x_train_new, y_train_new = smote_enn_method(x_train,y_train,neighbour)\n",
    "\n",
    "    if method_name == 'smotetomek':\n",
    "        # Apply SMOTETOMEK\n",
    "        x_train_new, y_train_new = smote_tomek_method(x_train,y_train,neighbour)\n",
    "    \n",
    "    \n",
    "    return x_train_new, y_train_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655e7152",
   "metadata": {},
   "source": [
    "# Sampling and Training with Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b18311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_processing(neighbour):\n",
    "    x_train_new, y_train_new = sampling_method(mth, neighbour, x_train, y_train)\n",
    "\n",
    "    model = train_all_models(x_train_new, y_train_new, model_name)\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred_train, y_pred_test, y_pred_test_proba = prediction(model, x_train_new, x_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    model_evaluation = Evaluation(y_train_new, y_test, y_pred_train, y_pred_test, y_pred_test_proba)\n",
    "\n",
    "    all_metrics,_ = model_evaluation.main()\n",
    "    all_metrics.insert(0, model_name)\n",
    "    all_metrics.insert(1, mth)\n",
    "    all_metrics.insert(2, neighbour)\n",
    "\n",
    "#     if neighbour%100 == 0 or neighbour == 1:\n",
    "#     print(\"{:<6} :: Train Acc: {:<14} :: Test Acc: {}\".format(neighbour, all_metrics[3], all_metrics[4]))\n",
    "#         print('.', end='')   \n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33ddfe",
   "metadata": {},
   "source": [
    "# Training with numerical data only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed355a",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28492555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "RowNumber                                                                  \n",
       "1                  619   42       2       0.00              1          1   \n",
       "2                  608   41       1   83807.86              1          0   \n",
       "3                  502   42       8  159660.80              3          1   \n",
       "4                  699   39       1       0.00              2          0   \n",
       "5                  850   43       2  125510.82              1          1   \n",
       "\n",
       "           IsActiveMember  EstimatedSalary  Exited  \n",
       "RowNumber                                           \n",
       "1                       1        101348.88       1  \n",
       "2                       1        112542.58       0  \n",
       "3                       0        113931.57       1  \n",
       "4                       0         93826.63       0  \n",
       "5                       1         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Drop all categorical columns\n",
    "df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be656b1",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3806d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16305e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>k_neighbour</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>ks_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>model</th>\n",
       "      <th>sampling_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approach_ada_BOOST</td>\n",
       "      <td>243</td>\n",
       "      <td>0.801256</td>\n",
       "      <td>0.7735</td>\n",
       "      <td>0.755377</td>\n",
       "      <td>0.917889</td>\n",
       "      <td>0.785938</td>\n",
       "      <td>0.846804</td>\n",
       "      <td>0.463836</td>\n",
       "      <td>0.724816</td>\n",
       "      <td>0.565676</td>\n",
       "      <td>0.526516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295</td>\n",
       "      <td>1252</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "      <td>ada_boost</td>\n",
       "      <td>borderline_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Approach_easy_ENSEMBLE</td>\n",
       "      <td>243</td>\n",
       "      <td>0.801256</td>\n",
       "      <td>0.7735</td>\n",
       "      <td>0.755377</td>\n",
       "      <td>0.917889</td>\n",
       "      <td>0.785938</td>\n",
       "      <td>0.846804</td>\n",
       "      <td>0.463836</td>\n",
       "      <td>0.724816</td>\n",
       "      <td>0.565676</td>\n",
       "      <td>0.526516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295</td>\n",
       "      <td>1252</td>\n",
       "      <td>341</td>\n",
       "      <td>112</td>\n",
       "      <td>easy_ensemble_classifier</td>\n",
       "      <td>borderline_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Approach_gradient_BOOSTING</td>\n",
       "      <td>354</td>\n",
       "      <td>0.819007</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.762049</td>\n",
       "      <td>0.917857</td>\n",
       "      <td>0.806654</td>\n",
       "      <td>0.858670</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>0.579940</td>\n",
       "      <td>0.525354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292</td>\n",
       "      <td>1285</td>\n",
       "      <td>308</td>\n",
       "      <td>115</td>\n",
       "      <td>gradient_boosting_classifier</td>\n",
       "      <td>adasyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Approach_lgbm_CLASSIFIER</td>\n",
       "      <td>486</td>\n",
       "      <td>0.895234</td>\n",
       "      <td>0.7830</td>\n",
       "      <td>0.753109</td>\n",
       "      <td>0.913633</td>\n",
       "      <td>0.803515</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.477462</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.568588</td>\n",
       "      <td>0.518287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286</td>\n",
       "      <td>1280</td>\n",
       "      <td>313</td>\n",
       "      <td>121</td>\n",
       "      <td>lgbm_classifier</td>\n",
       "      <td>smotetomek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Approach_hist_GRADIENT</td>\n",
       "      <td>354</td>\n",
       "      <td>0.862917</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.749710</td>\n",
       "      <td>0.912143</td>\n",
       "      <td>0.801632</td>\n",
       "      <td>0.853324</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.697789</td>\n",
       "      <td>0.564052</td>\n",
       "      <td>0.514629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284</td>\n",
       "      <td>1277</td>\n",
       "      <td>316</td>\n",
       "      <td>123</td>\n",
       "      <td>hist_gradient_boosting_classifier</td>\n",
       "      <td>adasyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Approach_balanced_RANDOM</td>\n",
       "      <td>244</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.747648</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.809793</td>\n",
       "      <td>0.856858</td>\n",
       "      <td>0.479381</td>\n",
       "      <td>0.685504</td>\n",
       "      <td>0.564206</td>\n",
       "      <td>0.501054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279</td>\n",
       "      <td>1290</td>\n",
       "      <td>303</td>\n",
       "      <td>128</td>\n",
       "      <td>balanced_random_forest_classifier</td>\n",
       "      <td>smotetomek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Approach_balanced_BAGGING</td>\n",
       "      <td>316</td>\n",
       "      <td>0.988383</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.733328</td>\n",
       "      <td>0.900758</td>\n",
       "      <td>0.820465</td>\n",
       "      <td>0.858739</td>\n",
       "      <td>0.479053</td>\n",
       "      <td>0.646192</td>\n",
       "      <td>0.550209</td>\n",
       "      <td>0.466656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>1307</td>\n",
       "      <td>286</td>\n",
       "      <td>144</td>\n",
       "      <td>balanced_bagging_classifier</td>\n",
       "      <td>borderline_smote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       method  k_neighbour  train_accuracy  test_accuracy  \\\n",
       "0          Approach_ada_BOOST          243        0.801256         0.7735   \n",
       "1      Approach_easy_ENSEMBLE          243        0.801256         0.7735   \n",
       "2  Approach_gradient_BOOSTING          354        0.819007         0.7885   \n",
       "3    Approach_lgbm_CLASSIFIER          486        0.895234         0.7830   \n",
       "4      Approach_hist_GRADIENT          354        0.862917         0.7805   \n",
       "5    Approach_balanced_RANDOM          244        0.999785         0.7845   \n",
       "6   Approach_balanced_BAGGING          316        0.988383         0.7850   \n",
       "\n",
       "    roc_auc  precision_0  recall_0      f1_0  precision_1  recall_1      f1_1  \\\n",
       "0  0.755377     0.917889  0.785938  0.846804     0.463836  0.724816  0.565676   \n",
       "1  0.755377     0.917889  0.785938  0.846804     0.463836  0.724816  0.565676   \n",
       "2  0.762049     0.917857  0.806654  0.858670     0.486667  0.717445  0.579940   \n",
       "3  0.753109     0.913633  0.803515  0.855043     0.477462  0.702703  0.568588   \n",
       "4  0.749710     0.912143  0.801632  0.853324     0.473333  0.697789  0.564052   \n",
       "5  0.747648     0.909732  0.809793  0.856858     0.479381  0.685504  0.564206   \n",
       "6  0.733328     0.900758  0.820465  0.858739     0.479053  0.646192  0.550209   \n",
       "\n",
       "    ks_stat  p_value   tp    tn   fp   fn                              model  \\\n",
       "0  0.526516      0.0  295  1252  341  112                          ada_boost   \n",
       "1  0.526516      0.0  295  1252  341  112           easy_ensemble_classifier   \n",
       "2  0.525354      0.0  292  1285  308  115       gradient_boosting_classifier   \n",
       "3  0.518287      0.0  286  1280  313  121                    lgbm_classifier   \n",
       "4  0.514629      0.0  284  1277  316  123  hist_gradient_boosting_classifier   \n",
       "5  0.501054      0.0  279  1290  303  128  balanced_random_forest_classifier   \n",
       "6  0.466656      0.0  263  1307  286  144        balanced_bagging_classifier   \n",
       "\n",
       "    sampling_method  \n",
       "0  borderline_smote  \n",
       "1  borderline_smote  \n",
       "2            adasyn  \n",
       "3        smotetomek  \n",
       "4            adasyn  \n",
       "5        smotetomek  \n",
       "6  borderline_smote  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = \"./final_results/potential_models/weights/fn_num/\"\n",
    "if not os.path.exists(loc):\n",
    "    os.makedirs(loc)\n",
    "\n",
    "pm = pd.read_csv(\"./final_results/potential_models/fn_num.csv\")\n",
    "pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "702918af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in pm.values:\n",
    "#     print(row)\n",
    "    mth = row[-1]\n",
    "    model_name = row[-2]\n",
    "    neighbour = row[1]\n",
    "    \n",
    "    metrics_data = []\n",
    "\n",
    "    x_train_new, y_train_new = sampling_method(mth, neighbour, x_train, y_train)\n",
    "\n",
    "    model = train_all_models(x_train_new, y_train_new, model_name)\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred_train, y_pred_test, y_pred_test_proba = prediction(model, x_train_new, x_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    model_evaluation = Evaluation(y_train_new, y_test, y_pred_train, y_pred_test, y_pred_test_proba)\n",
    "\n",
    "    all_metrics,_ = model_evaluation.main()\n",
    "    all_metrics.insert(0, model_name)\n",
    "    all_metrics.insert(1, mth)\n",
    "    all_metrics.insert(2, neighbour)\n",
    "\n",
    "    metrics_data = metrics_data + all_metrics\n",
    "    \n",
    "    if np.all(metrics_data[2:] == row[1:-2]) or model_name == 'catboost_classifier':\n",
    "        pickle.dump(model, open(os.path.join(loc, '_'.join(row[-2:]) + f'_{neighbour}.pkl'),'wb'))\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46077dfe",
   "metadata": {},
   "source": [
    "# Training with numerical and categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744facec",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "941f7060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1115</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177</td>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2040</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1822</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Surname  CreditScore  Geography  Gender  Age  Tenure    Balance  \\\n",
       "RowNumber                                                                    \n",
       "1             1115          619          0       0   42       2       0.00   \n",
       "2             1177          608          2       0   41       1   83807.86   \n",
       "3             2040          502          0       0   42       8  159660.80   \n",
       "4              289          699          0       0   39       1       0.00   \n",
       "5             1822          850          2       0   43       2  125510.82   \n",
       "\n",
       "           NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "RowNumber                                                                     \n",
       "1                      1          1               1        101348.88       1  \n",
       "2                      1          0               1        112542.58       0  \n",
       "3                      3          1               0        113931.57       1  \n",
       "4                      2          0               0         93826.63       0  \n",
       "5                      1          1               1         79084.10       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69aa4c",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994f0c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd160dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>k_neighbour</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>ks_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>model</th>\n",
       "      <th>sampling_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approach_lgbm_CLASSIFIER</td>\n",
       "      <td>907</td>\n",
       "      <td>0.899529</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>0.774847</td>\n",
       "      <td>0.916498</td>\n",
       "      <td>0.854363</td>\n",
       "      <td>0.884340</td>\n",
       "      <td>0.549515</td>\n",
       "      <td>0.695332</td>\n",
       "      <td>0.613883</td>\n",
       "      <td>0.550322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283</td>\n",
       "      <td>1361</td>\n",
       "      <td>232</td>\n",
       "      <td>124</td>\n",
       "      <td>lgbm_classifier</td>\n",
       "      <td>borderline_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Approach_gradient_BOOSTING</td>\n",
       "      <td>414</td>\n",
       "      <td>0.851823</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>0.768435</td>\n",
       "      <td>0.917361</td>\n",
       "      <td>0.829253</td>\n",
       "      <td>0.871085</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.707617</td>\n",
       "      <td>0.595657</td>\n",
       "      <td>0.550248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288</td>\n",
       "      <td>1321</td>\n",
       "      <td>272</td>\n",
       "      <td>119</td>\n",
       "      <td>gradient_boosting_classifier</td>\n",
       "      <td>adasyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Approach_ada_BOOST</td>\n",
       "      <td>375</td>\n",
       "      <td>0.829042</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.773268</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.821720</td>\n",
       "      <td>0.868613</td>\n",
       "      <td>0.509499</td>\n",
       "      <td>0.724816</td>\n",
       "      <td>0.598377</td>\n",
       "      <td>0.548993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295</td>\n",
       "      <td>1309</td>\n",
       "      <td>284</td>\n",
       "      <td>112</td>\n",
       "      <td>ada_boost</td>\n",
       "      <td>borderline_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Approach_easy_ENSEMBLE</td>\n",
       "      <td>375</td>\n",
       "      <td>0.829042</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.773268</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.821720</td>\n",
       "      <td>0.868613</td>\n",
       "      <td>0.509499</td>\n",
       "      <td>0.724816</td>\n",
       "      <td>0.598377</td>\n",
       "      <td>0.548993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295</td>\n",
       "      <td>1309</td>\n",
       "      <td>284</td>\n",
       "      <td>112</td>\n",
       "      <td>easy_ensemble_classifier</td>\n",
       "      <td>borderline_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Approach_balanced_RANDOM</td>\n",
       "      <td>254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.758168</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.845574</td>\n",
       "      <td>0.876383</td>\n",
       "      <td>0.526012</td>\n",
       "      <td>0.670762</td>\n",
       "      <td>0.589633</td>\n",
       "      <td>0.531842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273</td>\n",
       "      <td>1347</td>\n",
       "      <td>246</td>\n",
       "      <td>134</td>\n",
       "      <td>balanced_random_forest_classifier</td>\n",
       "      <td>smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Approach_balanced_BAGGING</td>\n",
       "      <td>200</td>\n",
       "      <td>0.989708</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.744968</td>\n",
       "      <td>0.902880</td>\n",
       "      <td>0.846202</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.516765</td>\n",
       "      <td>0.643735</td>\n",
       "      <td>0.573304</td>\n",
       "      <td>0.503491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262</td>\n",
       "      <td>1348</td>\n",
       "      <td>245</td>\n",
       "      <td>145</td>\n",
       "      <td>balanced_bagging_classifier</td>\n",
       "      <td>smotetomek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       method  k_neighbour  train_accuracy  test_accuracy  \\\n",
       "0    Approach_lgbm_CLASSIFIER          907        0.899529         0.8220   \n",
       "1  Approach_gradient_BOOSTING          414        0.851823         0.8045   \n",
       "2          Approach_ada_BOOST          375        0.829042         0.8020   \n",
       "3      Approach_easy_ENSEMBLE          375        0.829042         0.8020   \n",
       "4    Approach_balanced_RANDOM          254        1.000000         0.8100   \n",
       "5   Approach_balanced_BAGGING          200        0.989708         0.8050   \n",
       "\n",
       "    roc_auc  precision_0  recall_0      f1_0  precision_1  recall_1      f1_1  \\\n",
       "0  0.774847     0.916498  0.854363  0.884340     0.549515  0.695332  0.613883   \n",
       "1  0.768435     0.917361  0.829253  0.871085     0.514286  0.707617  0.595657   \n",
       "2  0.773268     0.921182  0.821720  0.868613     0.509499  0.724816  0.598377   \n",
       "3  0.773268     0.921182  0.821720  0.868613     0.509499  0.724816  0.598377   \n",
       "4  0.758168     0.909521  0.845574  0.876383     0.526012  0.670762  0.589633   \n",
       "5  0.744968     0.902880  0.846202  0.873623     0.516765  0.643735  0.573304   \n",
       "\n",
       "    ks_stat  p_value   tp    tn   fp   fn                              model  \\\n",
       "0  0.550322      0.0  283  1361  232  124                    lgbm_classifier   \n",
       "1  0.550248      0.0  288  1321  272  119       gradient_boosting_classifier   \n",
       "2  0.548993      0.0  295  1309  284  112                          ada_boost   \n",
       "3  0.548993      0.0  295  1309  284  112           easy_ensemble_classifier   \n",
       "4  0.531842      0.0  273  1347  246  134  balanced_random_forest_classifier   \n",
       "5  0.503491      0.0  262  1348  245  145        balanced_bagging_classifier   \n",
       "\n",
       "    sampling_method  \n",
       "0  borderline_smote  \n",
       "1            adasyn  \n",
       "2  borderline_smote  \n",
       "3  borderline_smote  \n",
       "4             smote  \n",
       "5        smotetomek  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = \"./final_results/potential_models/weights/fn_num_cat/\"\n",
    "if not os.path.exists(loc):\n",
    "    os.makedirs(loc)\n",
    "\n",
    "pm = pd.read_csv(\"./final_results/potential_models/fn_num_cat.csv\")\n",
    "pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8efee",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c504d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in pm.values:\n",
    "#     print(row)\n",
    "    mth = row[-1]\n",
    "    model_name = row[-2]\n",
    "    neighbour = row[1]\n",
    "    \n",
    "    metrics_data = []\n",
    "\n",
    "    x_train_new, y_train_new = sampling_method(mth, neighbour, x_train, y_train)\n",
    "\n",
    "    model = train_all_models(x_train_new, y_train_new, model_name)\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred_train, y_pred_test, y_pred_test_proba = prediction(model, x_train_new, x_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    model_evaluation = Evaluation(y_train_new, y_test, y_pred_train, y_pred_test, y_pred_test_proba)\n",
    "\n",
    "    all_metrics,_ = model_evaluation.main()\n",
    "    all_metrics.insert(0, model_name)\n",
    "    all_metrics.insert(1, mth)\n",
    "    all_metrics.insert(2, neighbour)\n",
    "\n",
    "    metrics_data = metrics_data + all_metrics\n",
    "    \n",
    "    if np.all(metrics_data[2:] == row[1:-2]) or model_name == 'catboost_classifier':\n",
    "        pickle.dump(model, open(os.path.join(loc, '_'.join(row[-2:]) + f'_{neighbour}.pkl'),'wb'))\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e44f22e",
   "metadata": {},
   "source": [
    "# Start Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785ddd3",
   "metadata": {},
   "source": [
    "# Ensemble Models\n",
    "\n",
    "### Combination of two models are used for creating ensemble models based on weightage to precision and recall for class 1.\n",
    "\n",
    "**Model 1** : Focus on decreasing FP.\n",
    "\n",
    "**Model 2** : Focus on decreasing FN.\n",
    "\n",
    "\n",
    "| Combination Name | Model 1                      | Model 2                      |\n",
    "| ---------------- | ---------------------------- | ---------------------------- |\n",
    "| Test 1           | numerical features only      | numerical features only      |\n",
    "| Test 2           | numerical + categorical features | numerical + categorical features |\n",
    "| Test 3           | categorical features treated as categorical** | categorical features treated as categorical** |\n",
    "| Test 4           | numerical features only      | numerical + categorical features |\n",
    "| Test 5           | numerical + categorical features | categorical features treated as categorical** |\n",
    "| Test 6           | categorical features treated as categorical** | numerical features only      |\n",
    "| Test 7           | numerical features only      | categorical features treated as categorical** |\n",
    "| Test 8           | numerical + categorical features | numerical features only      |\n",
    "| Test 9           | categorical features treated as categorical** | numerical + categorical features |\n",
    "\n",
    "\n",
    "**\\*\\*Valid for CatBoost model only**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3c14f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_num_models_loc = \"./final_results/potential_models/weights/fp_num/\"\n",
    "fp_num_cat_models_loc = \"./final_results/potential_models/weights/fp_num_cat/\"\n",
    "fp_cat_cat_models_loc = \"./final_results/potential_models/weights/fp_cat_cat/\"\n",
    "\n",
    "fn_num_models_loc = \"./final_results/potential_models/weights/fn_num/\"\n",
    "fn_num_cat_models_loc = \"./final_results/potential_models/weights/fn_num_cat/\"\n",
    "fn_cat_cat_models_loc = \"./final_results/potential_models/weights/fn_cat_cat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e0dd014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ensembler(model_1_name, model_2_name, variable_value):\n",
    "    # Assuming you have already trained and obtained predictions from both classifier models\n",
    "\n",
    "    ## Test Prediction\n",
    "    # Model 1 predictions\n",
    "    model_1_predictions_test = model_1.predict_proba(x_test)  # Assuming you're interested in class 1 prediction\n",
    "\n",
    "    # Gradient Boosting Classifier predictions\n",
    "    model_2_predictions_test = model_2.predict_proba(x_test)  # Assuming you're interested in class 1 prediction\n",
    "    \n",
    "    ## Train Prediction\n",
    "    # Model 1 predictions\n",
    "    model_1_predictions_train = model_1.predict_proba(x_train)  # Assuming you're interested in class 1 prediction\n",
    "\n",
    "    # Gradient Boosting Classifier predictions\n",
    "    model_2_predictions_train = model_2.predict_proba(x_train)  # Assuming you're interested in class 1 prediction\n",
    "\n",
    "\n",
    "    for i in i_range:\n",
    "        precision_weightage = round(i,ndigits=2)\n",
    "#         print(round(i,ndigits=3), end=' ')\n",
    "        for j in j_range:\n",
    "            recall_weightage = round(j,ndigits=2)\n",
    "#             print(round(j,ndigits=3), end=' ')\n",
    "#             for threshold in threshold_range:\n",
    "        \n",
    "            # Ensemble the models by weighted average\n",
    "            ensemble_predictions_test = (precision_weightage * model_1_predictions_test) + (recall_weightage * model_2_predictions_test)\n",
    "\n",
    "            # Threshold the ensemble predictions if necessary\n",
    "            ensemble_predictions_binary_test = np.where(ensemble_predictions_test >= threshold, 1, 0)\n",
    "\n",
    "            # Ensemble the models by weighted average\n",
    "            ensemble_predictions_train = (precision_weightage * model_1_predictions_train) + (recall_weightage * model_2_predictions_train)\n",
    "\n",
    "            # Threshold the ensemble predictions if necessary\n",
    "\n",
    "            ensemble_predictions_binary_train = np.where(ensemble_predictions_train >= threshold, 1, 0)\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            model_evaluation = Evaluation(y_train, y_test, \n",
    "                                          ensemble_predictions_binary_train[:,1], \n",
    "                                          ensemble_predictions_binary_test[:,1], \n",
    "                                          ensemble_predictions_test)\n",
    "            all_metrics, _ = model_evaluation.main()\n",
    "\n",
    "            all_metrics.insert(0, model_1_name)\n",
    "            all_metrics.insert(1, model_2_name)\n",
    "            all_metrics.insert(2,variable_value)\n",
    "            all_metrics.insert(3, precision_weightage)\n",
    "            all_metrics.insert(4, recall_weightage)\n",
    "            all_metrics.insert(5, threshold)\n",
    "\n",
    "\n",
    "            metrics_data.append(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3bfe67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ensembler_1(model_1_name, model_2_name, variable_value):\n",
    "    # Assuming you have already trained and obtained predictions from both classifier models\n",
    "\n",
    "    ## Test Prediction\n",
    "    # Model 1 predictions\n",
    "    model_1_predictions_test = model_1.predict_proba(x_test.drop(['Surname','Geography', 'Gender'], axis=1))  # Assuming you're interested in class 1 prediction\n",
    "\n",
    "    # Gradient Boosting Classifier predictions\n",
    "    model_2_predictions_test = model_2.predict_proba(x_test)  # Assuming you're interested in class 1 prediction\n",
    "    \n",
    "    ## Train Prediction\n",
    "    # Model 1 predictions\n",
    "    model_1_predictions_train = model_1.predict_proba(x_train.drop(['Surname','Geography', 'Gender'], axis=1))  # Assuming you're interested in class 1 prediction\n",
    "\n",
    "    # Gradient Boosting Classifier predictions\n",
    "    model_2_predictions_train = model_2.predict_proba(x_train)  # Assuming you're interested in class 1 prediction\n",
    "\n",
    "    for i in i_range:\n",
    "        precision_weightage = round(i, ndigits=2)\n",
    "#         print(round(i,ndigits=3), end=' ')\n",
    "        for j in j_range:\n",
    "            recall_weightage = round(j,ndigits=2)\n",
    "#             for threshold in threshold_range:\n",
    "\n",
    "    #             print(round(j,ndigits=3), end=' ')\n",
    "\n",
    "            # Ensemble the models by weighted average\n",
    "            ensemble_predictions_test = (precision_weightage * model_1_predictions_test) + (recall_weightage * model_2_predictions_test)\n",
    "\n",
    "            # Threshold the ensemble predictions if necessary\n",
    "            ensemble_predictions_binary_test = np.where(ensemble_predictions_test >= threshold, 1, 0)\n",
    "\n",
    "            # Ensemble the models by weighted average\n",
    "            ensemble_predictions_train = (precision_weightage * model_1_predictions_train) + (recall_weightage * model_2_predictions_train)\n",
    "\n",
    "            # Threshold the ensemble predictions if necessary\n",
    "\n",
    "            ensemble_predictions_binary_train = np.where(ensemble_predictions_train >= threshold, 1, 0)\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            model_evaluation = Evaluation(y_train, y_test, \n",
    "                                          ensemble_predictions_binary_train[:,1], \n",
    "                                          ensemble_predictions_binary_test[:,1], \n",
    "                                          ensemble_predictions_test)\n",
    "            all_metrics, _ = model_evaluation.main()\n",
    "\n",
    "            all_metrics.insert(0, model_1_name)\n",
    "            all_metrics.insert(1, model_2_name)\n",
    "            all_metrics.insert(2, variable_value)\n",
    "            all_metrics.insert(3, precision_weightage)\n",
    "            all_metrics.insert(4, recall_weightage)\n",
    "            all_metrics.insert(5, threshold)\n",
    "\n",
    "\n",
    "            metrics_data.append(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d6d71c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_range = j_range = np.arange(0.1,1.0, 0.01)\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78acf8e3",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c843fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# Drop all categorical columns\n",
    "df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533c58c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_random_forest_classifier_smoten_375.pkl\n",
      "\t ada_boost_borderline_smote_243.pkl\n",
      "\t gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t hist_gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_243.pkl\n",
      "\t lgbm_classifier_smotetomek_486.pkl\n",
      "\t balanced_bagging_classifier_borderline_smote_316.pkl\n",
      "\t balanced_random_forest_classifier_smotetomek_244.pkl\n",
      "hist_gradient_boosting_classifier_smoten_376.pkl\n",
      "\t ada_boost_borderline_smote_243.pkl\n",
      "\t gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t hist_gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_243.pkl\n",
      "\t lgbm_classifier_smotetomek_486.pkl\n",
      "\t balanced_bagging_classifier_borderline_smote_316.pkl\n",
      "\t balanced_random_forest_classifier_smotetomek_244.pkl\n",
      "gradient_boosting_classifier_smoten_820.pkl\n",
      "\t ada_boost_borderline_smote_243.pkl\n",
      "\t gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t hist_gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_243.pkl\n",
      "\t lgbm_classifier_smotetomek_486.pkl\n",
      "\t balanced_bagging_classifier_borderline_smote_316.pkl\n",
      "\t balanced_random_forest_classifier_smotetomek_244.pkl\n",
      "easy_ensemble_classifier_smoten_949.pkl\n",
      "\t ada_boost_borderline_smote_243.pkl\n",
      "\t gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t hist_gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_243.pkl\n",
      "\t lgbm_classifier_smotetomek_486.pkl\n",
      "\t balanced_bagging_classifier_borderline_smote_316.pkl\n",
      "\t balanced_random_forest_classifier_smotetomek_244.pkl\n",
      "lgbm_classifier_smoten_1215.pkl\n",
      "\t ada_boost_borderline_smote_243.pkl\n",
      "\t gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t hist_gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_243.pkl\n",
      "\t lgbm_classifier_smotetomek_486.pkl\n",
      "\t balanced_bagging_classifier_borderline_smote_316.pkl\n",
      "\t balanced_random_forest_classifier_smotetomek_244.pkl\n",
      "ada_boost_smoten_949.pkl\n",
      "\t ada_boost_borderline_smote_243.pkl\n",
      "\t gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t hist_gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_243.pkl\n",
      "\t lgbm_classifier_smotetomek_486.pkl\n",
      "\t balanced_bagging_classifier_borderline_smote_316.pkl\n",
      "\t balanced_random_forest_classifier_smotetomek_244.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics_data = []\n",
    "# st = time()\n",
    "for model_1_name in os.listdir(fp_num_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fp_num_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fn_num_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fn_num_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "        \n",
    "        model_ensembler(model_1_name, model_2_name, 'num_num')\n",
    "        \n",
    "\n",
    "                \n",
    "                \n",
    "#         break\n",
    "#     break\n",
    "# et = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45e27990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.80266737937927"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5487484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data_columns = ['model_1','model_2','type', 'precision_weight', 'recall_weight', 'threshold' ,\n",
    "                         'train_accuracy', 'test_accuracy', 'roc_auc',\n",
    "                         'precision_0', 'recall_0', 'f1_0',\n",
    "                         'precision_1', 'recall_1', 'f1_1', \n",
    "                         'ks_stat', 'p_value', \n",
    "                         'tp', 'tn', 'fp', 'fn']\n",
    "\n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_1.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a6a32",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4298eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e99df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_bagging_classifier_smoten_290.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "catboost_classifier_smoten_818.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "extra_trees_classifier_smoten_405.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "lgbm_classifier_smoten_1208.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "random_forest_classifier_smoten_466.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "easy_ensemble_classifier_smoten_844.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "ada_boost_smoten_950.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics_data = []\n",
    "\n",
    "for model_1_name in os.listdir(fp_num_cat_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fp_num_cat_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fn_num_cat_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fn_num_cat_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "\n",
    "        model_ensembler(model_1_name, model_2_name, 'num_cat')\n",
    "                \n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f893831",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data_columns = ['model_1','model_2','type', 'precision_weight', 'recall_weight', 'threshold' ,\n",
    "                         'train_accuracy', 'test_accuracy', 'roc_auc',\n",
    "                         'precision_0', 'recall_0', 'f1_0',\n",
    "                         'precision_1', 'recall_1', 'f1_1', \n",
    "                         'ks_stat', 'p_value', \n",
    "                         'tp', 'tn', 'fp', 'fn']\n",
    "\n",
    "\n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_2.csv\", index=False, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28cf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "757a18ea",
   "metadata": {},
   "source": [
    "## Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76d715dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost_classifier_smoten_1201.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "catboost_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "catboost_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "catboost_classifier_smoten_285.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "catboost_classifier_smoten_384.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n"
     ]
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "\n",
    "metrics_data = []\n",
    "\n",
    "for model_1_name in os.listdir(fp_cat_cat_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fp_cat_cat_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fn_cat_cat_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fn_cat_cat_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "        \n",
    "        model_ensembler(model_1_name, model_2_name, 'cat_cat')\n",
    "                \n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_3.csv\", index=False, header=True)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa000e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8733a75",
   "metadata": {},
   "source": [
    "## Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4679c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31ae630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_random_forest_classifier_smoten_375.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "hist_gradient_boosting_classifier_smoten_376.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "gradient_boosting_classifier_smoten_820.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "easy_ensemble_classifier_smoten_949.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "lgbm_classifier_smoten_1215.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "ada_boost_smoten_949.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n"
     ]
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "\n",
    "metrics_data = []\n",
    "\n",
    "for model_1_name in os.listdir(fp_num_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fp_num_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fn_num_cat_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fn_num_cat_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "        \n",
    "        model_ensembler_1(model_1_name, model_2_name, 'num_num_num_cat')\n",
    "                \n",
    "        \n",
    "#     break\n",
    "\n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_4.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bba351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1650a126",
   "metadata": {},
   "source": [
    "## Test 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61a6dbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_bagging_classifier_smoten_290.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "catboost_classifier_smoten_818.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "extra_trees_classifier_smoten_405.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "lgbm_classifier_smoten_1208.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "random_forest_classifier_smoten_466.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "easy_ensemble_classifier_smoten_844.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "ada_boost_smoten_950.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n"
     ]
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "\n",
    "metrics_data = []\n",
    "\n",
    "for model_1_name in os.listdir(fp_num_cat_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fp_num_cat_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fn_cat_cat_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fn_cat_cat_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "        \n",
    "        model_ensembler(model_1_name, model_2_name, 'num_cat_cat_cat')\n",
    "                \n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_5.csv\", index=False, header=True)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c94f3",
   "metadata": {},
   "source": [
    "## TEst 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c48700ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_boost_borderline_smote_243.pkl\n",
      "\t catboost_classifier_smoten_1201.pkl\n",
      "\t catboost_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoten_285.pkl\n",
      "\t catboost_classifier_smoten_384.pkl\n",
      "gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t catboost_classifier_smoten_1201.pkl\n",
      "\t catboost_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoten_285.pkl\n",
      "\t catboost_classifier_smoten_384.pkl\n",
      "hist_gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t catboost_classifier_smoten_1201.pkl\n",
      "\t catboost_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoten_285.pkl\n",
      "\t catboost_classifier_smoten_384.pkl\n",
      "easy_ensemble_classifier_borderline_smote_243.pkl\n",
      "\t catboost_classifier_smoten_1201.pkl\n",
      "\t catboost_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoten_285.pkl\n",
      "\t catboost_classifier_smoten_384.pkl\n",
      "lgbm_classifier_smotetomek_486.pkl\n",
      "\t catboost_classifier_smoten_1201.pkl\n",
      "\t catboost_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoten_285.pkl\n",
      "\t catboost_classifier_smoten_384.pkl\n",
      "balanced_bagging_classifier_borderline_smote_316.pkl\n",
      "\t catboost_classifier_smoten_1201.pkl\n",
      "\t catboost_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoten_285.pkl\n",
      "\t catboost_classifier_smoten_384.pkl\n",
      "balanced_random_forest_classifier_smotetomek_244.pkl\n",
      "\t catboost_classifier_smoten_1201.pkl\n",
      "\t catboost_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoten_285.pkl\n",
      "\t catboost_classifier_smoten_384.pkl\n"
     ]
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "\n",
    "metrics_data = []\n",
    "\n",
    "for model_1_name in os.listdir(fn_num_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fn_num_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fp_cat_cat_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fp_cat_cat_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "        \n",
    "        model_ensembler_1(model_1_name, model_2_name, 'cat_cat_num_num')\n",
    "                \n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_6.csv\", index=False, header=True)    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26982d",
   "metadata": {},
   "source": [
    "## Test 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97a5d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_random_forest_classifier_smoten_375.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "hist_gradient_boosting_classifier_smoten_376.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "gradient_boosting_classifier_smoten_820.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "easy_ensemble_classifier_smoten_949.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "lgbm_classifier_smoten_1215.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n",
      "ada_boost_smoten_949.pkl\n",
      "\t catboost_classifier_smoteenn_457.pkl\n"
     ]
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "\n",
    "metrics_data = []\n",
    "\n",
    "for model_1_name in os.listdir(fp_num_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fp_num_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fn_cat_cat_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fn_cat_cat_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "        \n",
    "        model_ensembler_1(model_1_name, model_2_name, 'num_num_cat_cat')\n",
    "                \n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_7.csv\", index=False, header=True)     \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dce3ea",
   "metadata": {},
   "source": [
    "## Test 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bed31320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_boost_borderline_smote_243.pkl\n",
      "\t balanced_bagging_classifier_smoten_290.pkl\n",
      "\t catboost_classifier_smoten_818.pkl\n",
      "\t extra_trees_classifier_smoten_405.pkl\n",
      "\t lgbm_classifier_smoten_1208.pkl\n",
      "\t balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t random_forest_classifier_smoten_466.pkl\n",
      "\t easy_ensemble_classifier_smoten_844.pkl\n",
      "\t ada_boost_smoten_950.pkl\n",
      "gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t balanced_bagging_classifier_smoten_290.pkl\n",
      "\t catboost_classifier_smoten_818.pkl\n",
      "\t extra_trees_classifier_smoten_405.pkl\n",
      "\t lgbm_classifier_smoten_1208.pkl\n",
      "\t balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t random_forest_classifier_smoten_466.pkl\n",
      "\t easy_ensemble_classifier_smoten_844.pkl\n",
      "\t ada_boost_smoten_950.pkl\n",
      "hist_gradient_boosting_classifier_adasyn_354.pkl\n",
      "\t balanced_bagging_classifier_smoten_290.pkl\n",
      "\t catboost_classifier_smoten_818.pkl\n",
      "\t extra_trees_classifier_smoten_405.pkl\n",
      "\t lgbm_classifier_smoten_1208.pkl\n",
      "\t balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t random_forest_classifier_smoten_466.pkl\n",
      "\t easy_ensemble_classifier_smoten_844.pkl\n",
      "\t ada_boost_smoten_950.pkl\n",
      "easy_ensemble_classifier_borderline_smote_243.pkl\n",
      "\t balanced_bagging_classifier_smoten_290.pkl\n",
      "\t catboost_classifier_smoten_818.pkl\n",
      "\t extra_trees_classifier_smoten_405.pkl\n",
      "\t lgbm_classifier_smoten_1208.pkl\n",
      "\t balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t random_forest_classifier_smoten_466.pkl\n",
      "\t easy_ensemble_classifier_smoten_844.pkl\n",
      "\t ada_boost_smoten_950.pkl\n",
      "lgbm_classifier_smotetomek_486.pkl\n",
      "\t balanced_bagging_classifier_smoten_290.pkl\n",
      "\t catboost_classifier_smoten_818.pkl\n",
      "\t extra_trees_classifier_smoten_405.pkl\n",
      "\t lgbm_classifier_smoten_1208.pkl\n",
      "\t balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t random_forest_classifier_smoten_466.pkl\n",
      "\t easy_ensemble_classifier_smoten_844.pkl\n",
      "\t ada_boost_smoten_950.pkl\n",
      "balanced_bagging_classifier_borderline_smote_316.pkl\n",
      "\t balanced_bagging_classifier_smoten_290.pkl\n",
      "\t catboost_classifier_smoten_818.pkl\n",
      "\t extra_trees_classifier_smoten_405.pkl\n",
      "\t lgbm_classifier_smoten_1208.pkl\n",
      "\t balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t random_forest_classifier_smoten_466.pkl\n",
      "\t easy_ensemble_classifier_smoten_844.pkl\n",
      "\t ada_boost_smoten_950.pkl\n",
      "balanced_random_forest_classifier_smotetomek_244.pkl\n",
      "\t balanced_bagging_classifier_smoten_290.pkl\n",
      "\t catboost_classifier_smoten_818.pkl\n",
      "\t extra_trees_classifier_smoten_405.pkl\n",
      "\t lgbm_classifier_smoten_1208.pkl\n",
      "\t balanced_random_forest_classifier_smoten_821.pkl\n",
      "\t gradient_boosting_classifier_smoten_1173.pkl\n",
      "\t random_forest_classifier_smoten_466.pkl\n",
      "\t easy_ensemble_classifier_smoten_844.pkl\n",
      "\t ada_boost_smoten_950.pkl\n"
     ]
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "\n",
    "metrics_data = []\n",
    "\n",
    "for model_1_name in os.listdir(fn_num_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fn_num_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fp_num_cat_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fp_num_cat_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "\n",
    "        model_ensembler_1(model_1_name, model_2_name, 'num_cat_num_num')\n",
    "                \n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_8.csv\", index=False, header=True)        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e52df",
   "metadata": {},
   "source": [
    "## Test 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d335443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost_classifier_smoten_1201.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "catboost_classifier_smoten_375.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "catboost_classifier_smoten_376.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "catboost_classifier_smoten_285.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n",
      "catboost_classifier_smoten_384.pkl\n",
      "\t lgbm_classifier_borderline_smote_907.pkl\n",
      "\t ada_boost_borderline_smote_375.pkl\n",
      "\t balanced_random_forest_classifier_smote_254.pkl\n",
      "\t gradient_boosting_classifier_adasyn_414.pkl\n",
      "\t balanced_bagging_classifier_smotetomek_200.pkl\n",
      "\t easy_ensemble_classifier_borderline_smote_375.pkl\n"
     ]
    }
   ],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# Converting type of columns to category\n",
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')\n",
    "df['Surname'] = df['Surname'].astype('category')\n",
    "\n",
    "# Assigning numerical values and storing it in another columns\n",
    "df['Geography_new'] = df['Geography'].cat.codes\n",
    "df['Gender_new'] = df['Gender'].cat.codes\n",
    "df['Surname_new'] = df['Surname'].cat.codes\n",
    "\n",
    "df['Geography'] = df['Geography_new']\n",
    "df['Gender'] = df['Gender_new']\n",
    "df['Surname'] = df['Surname_new']\n",
    "\n",
    "df.drop(['CustomerId', 'Surname_new','Geography_new', 'Gender_new'], axis = 1,inplace=True)\n",
    "# df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Split the DataFrame into features and target variables.\n",
    "x,y = features_target_split(df)\n",
    "\n",
    "# Split the features and target variables into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,df)\n",
    "\n",
    "\n",
    "metrics_data = []\n",
    "\n",
    "for model_1_name in os.listdir(fp_cat_cat_models_loc):\n",
    "    model_1 = pickle.load(open(os.path.join(fp_cat_cat_models_loc, model_1_name), 'rb'))\n",
    "    print(model_1_name)\n",
    "    \n",
    "    for model_2_name in os.listdir(fn_num_cat_models_loc):\n",
    "        model_2 = pickle.load(open(os.path.join(fn_num_cat_models_loc, model_2_name), 'rb'))\n",
    "        print('\\t',model_2_name)\n",
    "        \n",
    "        model_ensembler(model_1_name, model_2_name, 'cat_cat_num_cat')\n",
    "                \n",
    "pd.DataFrame(metrics_data, columns=metrics_data_columns).to_csv(\"../Desktop/test_9.csv\", index=False, header=True)        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d263d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d31c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
